{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdKtb8Zuserg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np \n",
    "import random\n",
    "import time \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Start with vgg19\n",
    "from tensorflow.keras.applications import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "aSI_e9cXwuwy",
    "outputId": "0bd80b74-4dd5-4a51-c28b-37a43661bf91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bSedF9rSwxBp",
    "outputId": "0379d6f7-1a1d-4e6d-a45c-7f37c217db8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accelerators:  1\n"
     ]
    }
   ],
   "source": [
    "try: # detect TPUs\n",
    "    # detect and init the TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    # instantiate a distribution strategy\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "IMAGEDIR = 'ParentImages/'\n",
    "OUTDIR = 'Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JemWzyojPynP"
   },
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return PIL.Image.fromarray(tensor)\n",
    "\n",
    "def load_img_x(path_to_img):\n",
    "    max_dim = 512\n",
    "    img = tf.io.read_file(path_to_img)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    #resize\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "mpXpewumuAtN",
    "outputId": "fb69c0a3-ce25-44ed-d73b-fba995c76aff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Airedale', 0.8730491),\n",
       " ('Lakeland_terrier', 0.067905225),\n",
       " ('Irish_terrier', 0.024518188),\n",
       " ('wire-haired_fox_terrier', 0.022631524),\n",
       " ('standard_poodle', 0.005026559)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the primary image to explore\n",
    "content_path = IMAGEDIR+'Bacchus.jpg'\n",
    "\n",
    "content = load_img_x(content_path)\n",
    "tnew = vgg19.preprocess_input(content*255)\n",
    "tnew = tf.image.resize(tnew, (224, 224))\n",
    "# first test full VGG19\n",
    "model = vgg19.VGG19(include_top=True, weights='imagenet')\n",
    "probs = model(tnew)\n",
    "probs.shape\n",
    "top_5 = vgg19.decode_predictions(probs.numpy())[0]\n",
    "[(class_name, prob) for (number, class_name, prob) in top_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Fsy3iPcutcH"
   },
   "outputs": [],
   "source": [
    "# well, he is a welshie, but we can forgive mistaking him for an airedale\n",
    "model = vgg19.VGG19(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TDxgEyPVIh9"
   },
   "outputs": [],
   "source": [
    "# loss functions\n",
    "## content loss\n",
    "def mat_loss(target, combo, scale = 1):\n",
    "    # this is just pixel distance (squared)\n",
    "    return K.sum(K.square(target-combo))/scale \n",
    "\n",
    "\"\"\" The gram matrix captures the style of an image.\n",
    "    In essence it takes a pixel image h x w x n_f, where h and w are the height and width of \n",
    "    the image, and converts it into a n_f x n_f matrix that is a measure of may many of the \n",
    "    layer features have been represented in that image.  Minimizing the gram matrix distances \n",
    "    between the style and combo will be this loss.\n",
    "\"\"\"\n",
    "def gram_matrix(x):\n",
    "    return tf.linalg.einsum('bijc,bijd->bcd', x, x)\n",
    "\n",
    "## style loss\n",
    "## in practice, style loss is computed using mat_loss above\n",
    "def style_loss(style, combo):\n",
    "    gram_sty = gram_matrix(style)\n",
    "    gram_com = gram_matrix(combo)\n",
    "    return K.sum(K.square(gram_sty-gram_com))\n",
    "\n",
    "## total variational loss\n",
    "## encourages pixel continuity in the combo image\n",
    "def variational_loss(combo, diag_weight = 0.5):\n",
    "    # this is just pixel distance (squared)\n",
    "    A = K.square(combo[:,:-1,1:,:] - combo[:,1:,1:,:])\n",
    "    B = K.square(combo[:,1:,:-1,:] - combo[:,1:,1:,:])\n",
    "    C = K.square(combo[:,:-1,:-1,:] - combo[:,1:,1:,:])\n",
    "    D = K.square(combo[:,:-1,1:,:] - combo[:,1:,:-1,:])\n",
    "    # several sources raise this to the 1.25 power - I have no idea why and have been unable\n",
    "    # to locate an original source (doesn't seem to matter though)\n",
    "    return K.sum(A+B+diag_weight*(C+D))\n",
    "\n",
    "# clip to float 0-1\n",
    "def clip_f(image):\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "pjTeE3A6wHtC",
    "outputId": "063a0119-32ca-449c-e816-c539957abf99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# what are the vgg19 layer names\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTrxqQrhvwCM"
   },
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name,layer.output) for layer in model.layers])\n",
    "style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
    "content_layers = ['block5_conv2']\n",
    "\n",
    "num_content_layers = len(content_layers)\n",
    "num_style_layers = len(style_layers)\n",
    "\n",
    "# get untrainable vgg19 for layer extraction\n",
    "def vgg_layers(layer_names):\n",
    "    vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "    model = Model([vgg.input], outputs)\n",
    "    return model\n",
    "\n",
    "# this is the heavy lifter (adapted from tf website)\n",
    "class NeuralStyleTransferModel(Model):\n",
    "    def __init__(self, style_layers, content_layers):\n",
    "        super(NeuralStyleTransferModel, self).__init__()\n",
    "        self.vgg =  vgg_layers(style_layers + content_layers)\n",
    "        self.style_layers = style_layers\n",
    "        self.content_layers = content_layers\n",
    "        self.num_style_layers = len(style_layers)\n",
    "        self.num_content_layers = len(content_layers)\n",
    "        self.vgg.trainable = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #float input in [0,1]\n",
    "        inputs = inputs*255.0\n",
    "        preprocessed_input = vgg19.preprocess_input(inputs)\n",
    "        outputs = self.vgg(preprocessed_input)\n",
    "        style_outputs, content_outputs = (outputs[:self.num_style_layers], outputs[self.num_style_layers:])\n",
    "\n",
    "        # get gram matrix for style, combine with combo image later\n",
    "        style_outputs = [gram_matrix(style_output)\n",
    "                        for style_output in style_outputs]\n",
    "\n",
    "        content_dict = {content_name:value \n",
    "                        for content_name, value \n",
    "                        in zip(self.content_layers, content_outputs)}\n",
    "\n",
    "        style_dict = {style_name:value\n",
    "                    for style_name, value\n",
    "                    in zip(self.style_layers, style_outputs)}\n",
    "    \n",
    "        return {'content':content_dict, 'style':style_dict}\n",
    "\n",
    "# define the extractor model\n",
    "extractor = NeuralStyleTransferModel(style_layers, content_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYwV4amExJqF"
   },
   "outputs": [],
   "source": [
    "def get_mean_weights(s_out, c_out, combo_image, regulator=0.1,meanofall=False):\n",
    "    \"\"\"compute the mean of style, content and var, \n",
    "    and use that to weight the values\n",
    "    \"\"\"\n",
    "    #size of combo image\n",
    "    xshape = tf.shape(combo_image)\n",
    "    dof = np.float32(xshape[-3]*xshape[-2]*xshape[-1])\n",
    "    # this is the factor against which all others will be normalized\n",
    "    var_factor = variational_loss(combo_image)/dof + 1e-8\n",
    "    # define the dictionary\n",
    "    weight_dict = {\"variation\": 1}\n",
    "    # compute style weights\n",
    "    net_mean=0\n",
    "    ix = 0\n",
    "    for name, output in sorted(s_out.items()):\n",
    "        xr = output.numpy().shape\n",
    "        n_c = 1\n",
    "        for x in xr:\n",
    "            n_c *= x \n",
    "        weight = output.numpy().mean()**2 * n_c / var_factor\n",
    "        net_mean += output.numpy().mean()\n",
    "        ix+=1\n",
    "        if weight == 0: \n",
    "            weight = regulator / var_factor\n",
    "        weight_dict[name] = weight\n",
    "    if meanofall:\n",
    "        for name, output in sorted(s_out.items()):\n",
    "            xr = output.numpy().shape\n",
    "            n_c = 1\n",
    "            for x in xr:\n",
    "                n_c *= x \n",
    "            weight_dict[name] = net_mean**2 * n_c / (var_factor * ix**2)\n",
    "    # compute content weights\n",
    "    net_mean=0\n",
    "    ix = 0\n",
    "    for name, output in sorted(c_out.items()):\n",
    "        xr = output.numpy().shape\n",
    "        n_c = 1\n",
    "        for x in xr:\n",
    "            n_c *= x \n",
    "        weight = output.numpy().mean()**2 * n_c / var_factor\n",
    "        net_mean += output.numpy().mean()\n",
    "        ix+=1\n",
    "        if weight == 0: \n",
    "            weight = regulator / var_factor\n",
    "        weight_dict[name] = weight\n",
    "    if meanofall:\n",
    "        for name, output in sorted(s_out.items()):\n",
    "            xr = output.numpy().shape\n",
    "            n_c = 1\n",
    "            for x in xr:\n",
    "                n_c *= x \n",
    "            weight_dict[name] = net_mean**2 * n_c / (var_factor * ix**2)\n",
    "    return weight_dict\n",
    "\n",
    "# this is our master function: path it a content and style image, and enjoy \n",
    "def build_image(content_path,style_path, weights = None, powers = None, abort_thresh = 0.0001,\n",
    "                beta1 = 0.99, beta2 = 0.999, lr = 0.01, epochs=10, \n",
    "                useMeanWeighting = False, contentStart = True):\n",
    "    c_w,s_w,v_w = 1,1,1\n",
    "    c_p,s_p,v_p = 1,1,1\n",
    "    if weights is not None:\n",
    "        [c_w,s_w,v_w]=weights\n",
    "    if powers is not None:\n",
    "        [c_p,s_p,v_p]=powers\n",
    "\n",
    "    content_image = load_img_x(content_path)\n",
    "    xshape = tf.shape(content_image)\n",
    "    dof = np.float32(xshape[-3]*xshape[-2]*xshape[-1])\n",
    "    style_image = tf.image.resize(load_img_x(style_path),(xshape[1],xshape[2]))\n",
    "\n",
    "    # Extract base image vgg outputs only once - they won't change \n",
    "    style_outs = extractor(style_image)['style']\n",
    "    content_outs = extractor(content_image)['content']\n",
    "    combo_image = tf.Variable(content_image)\n",
    "    if contentStart == False:\n",
    "        combo_image = tf.Variable(tf.random.uniform(shape = xshape))\n",
    "\n",
    "    weightdict = get_mean_weights(style_outs,content_outs,combo_image)\n",
    "    if useMeanWeighting:\n",
    "        weightdict = get_mean_weights(style_outs,content_outs,combo_image,meanofall=True)\n",
    "\n",
    "\n",
    "    # note: insanely sensitive to hyperparameter choices\n",
    "    # the original paper uses L-BFGS\n",
    "    opt = tf.optimizers.Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2, epsilon=1e-7)\n",
    "    \n",
    "    def total_loss(combo):\n",
    "        # using adam, this won't matter, if SGD, dial it\n",
    "        scale = 1\n",
    "        # get the style and content for the combined image\n",
    "        outputs = extractor(combo)\n",
    "        style_outputs = outputs['style']\n",
    "        content_outputs = outputs['content']\n",
    "\n",
    "        # compute style loss on all style layers\n",
    "        style_loss = tf.add_n([mat_loss(style_outputs[name],style_outs[name], \n",
    "                                        scale=weightdict[name])\n",
    "                                for name in style_outputs.keys()])\n",
    "        # compute content loss on all content layers\n",
    "        content_loss = tf.add_n([mat_loss(content_outputs[name],content_outs[name], \n",
    "                                          scale=weightdict[name])\n",
    "                                    for name in content_outputs.keys()])\n",
    "        # compute variational loss on the combo image\n",
    "        var_loss = variational_loss(combo) / dof\n",
    "        # join all losses using specified weights and powers\n",
    "        loss = s_w * (style_loss ** s_p) + c_w * (content_loss ** c_p) + v_w * (var_loss ** v_p)\n",
    "        return scale * loss\n",
    "\n",
    "    #@tf.function()\n",
    "    def train_step(im):\n",
    "        # GradientTape context tracks coputations for gradient back-prop\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = total_loss(im)\n",
    "        grad = tape.gradient(loss, im)\n",
    "        # using Adam here (perhaps recklessly)\n",
    "        opt.apply_gradients([(grad, im)])\n",
    "        # clip back to [0-1] range\n",
    "        im.assign(clip_f(im))\n",
    "        return loss\n",
    "\n",
    "    start = time.time()\n",
    "    steps_per_epoch = 50\n",
    "    step = 0\n",
    "    losses = []\n",
    "    # copy old combo image for early loop exit\n",
    "    oldim = tf.Variable(combo_image)\n",
    "    # epoch loop\n",
    "    for n in range(epochs):\n",
    "        for m in range(steps_per_epoch):\n",
    "            step += 1\n",
    "            losses.append(train_step(combo_image))\n",
    "            print(\".\", end='')\n",
    "        # clear output and display tensoe\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(tensor_to_image(combo_image))\n",
    "        #print(mat_loss(oldim,combo_image)/dof)\n",
    "        # if image is hardly changing, break loop (abort_thresh ~ 1e-4 is good)\n",
    "        # if using a low lr, decrease or set to zero\n",
    "        if mat_loss(oldim,combo_image)/dof < abort_thresh:\n",
    "            break;\n",
    "        # set for next rough\n",
    "        oldim =  tf.Variable(combo_image)\n",
    "    end = time.time()\n",
    "    print(\"Total time: {:.1f}\".format(end-start))\n",
    "    return combo_image, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQ36OsVYVwX5"
   },
   "source": [
    "# Generation\n",
    "\n",
    "lr, Beta1, and s,c,v_w,p are the important paramters  \n",
    "Basic plan:  \n",
    "1) leave lr / beta_1 at defaults, increasing lr or beta_1 can blur out patches  \n",
    "2) leave v_w and v_p at 1 unless image is too blurry or pixelated  \n",
    "3) s_w and s_p can all be 1 for good image  \n",
    "4) Set c_w = 0, start with content image, don't actually use it in the update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "urD80lzGVv4S",
    "outputId": "dd61a7bc-d7c5-453c-a0b4-219fd1e85dc4"
   },
   "outputs": [],
   "source": [
    "content_path = IMAGEDIR + 'Bacchus.jpg'\n",
    "style_path = IMAGEDIR + 'Gleizes_The_Bridges_of_Paris.jpg'\n",
    "style_path_0 = IMAGEDIR + 'Blue_Water_Lilies_Monet.jpg'\n",
    "style_path_1 = IMAGEDIR + 'Delaunay_Window_on_the_City.jpg'\n",
    "style_path_2 = IMAGEDIR + 'Christ_in_Limbo.jpg'\n",
    "style_path_3 = IMAGEDIR + 'Kandinsky_Composition_7.jpg'\n",
    "style_path_4 = IMAGEDIR + 'Babel_Bruegel.jpg'\n",
    "style_path_5 = IMAGEDIR + 'Wreckers_Coast_of_Northumberland_JMWTurner.jpg'\n",
    "style_path_6 = IMAGEDIR + 'Water_Lily_Pond_Monet.jpg'\n",
    "style_path_7 = IMAGEDIR + 'Tondals_Vision.jpg'\n",
    "style_path_8 = IMAGEDIR + 'The_Triumph_of_Death_Bruegel.jpg'\n",
    "style_path_9 = IMAGEDIR + 'Metzinger_Two_Nudes.jpg'\n",
    "\n",
    "\n",
    "[c_w,s_w,v_w] = [0,1,1]\n",
    "[c_p,s_p,v_p] = [1,1,1]\n",
    "[lr,beta1,beta2,epochs]=[0.01,0.98,0.9999,15]\n",
    "newim, losses = build_image(content_path,style_path_7,lr=lr,beta1=beta1,beta2=beta2,\n",
    "                            epochs=epochs,weights=[c_w,s_w,v_w],powers=[c_p,s_p,v_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_hB8fuSwBGO"
   },
   "outputs": [],
   "source": [
    "filename = 'Bacchus_Tondal1.jpg'\n",
    "plt.imsave(OUTDIR+filename,np.array(newim[0]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1ZLJdFGL0_23",
    "OFCcz8vTV5Q4",
    "kCfZupSoqG44",
    "zky_OiHNZmWe",
    "Z9yGvZG5Zitz",
    "dSTdv7cWWHff",
    "rxK7wIYkcwYK",
    "pPFi5vm5bQA8"
   ],
   "name": "CubistNST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
